"""Scanner for static analysis, MCPSafetyScanner, and Gemini 3 semantic analysis."""

from __future__ import annotations

import json
import logging
import os
import re
import shutil
import subprocess
import uuid
from datetime import datetime, timedelta, timezone
from hashlib import sha256
from pathlib import Path
from typing import Any
from urllib.parse import urlparse

import httpx
from pydantic import BaseModel, Field

from . import evidence, registry

logger = logging.getLogger(__name__)

GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-3-flash-preview")
GEMINI_API_KEY_ENV = "GOOGLE_API_KEY"


class ToolThreatAnalysis(BaseModel):
    """Gemini 3 structured output for a single tool threat."""

    tool_name: str = Field(description="Name of the analyzed tool")
    risk_level: str = Field(description="Risk level: critical, high, medium, low, safe")
    threat_type: str = Field(
        description="Threat category: data_exfiltration, privilege_escalation, "
        "command_injection, prompt_injection, resource_abuse, none"
    )
    description: str = Field(description="Brief description of the identified threat")
    confidence: float = Field(ge=0.0, le=1.0, description="Confidence in the assessment")


class SemanticScanResult(BaseModel):
    """Gemini 3 structured output for semantic scan."""

    overall_risk: str = Field(description="Overall risk: critical, high, medium, low, safe")
    tool_analyses: list[ToolThreatAnalysis] = Field(
        default_factory=list, description="Per-tool threat analysis"
    )
    summary: str = Field(description="Summary of findings in 1-3 sentences")
    recommended_action: str = Field(
        description="Recommended action: block, quarantine, allow_with_monitoring, allow"
    )

VERSION_RE = re.compile(r"^\d+\.\d+\.\d+(?:-[\w\.]+)?$")
MANIFEST_PATHS = ("/.well-known/mcp.json", "/mcp.json")
MANIFEST_TIMEOUT_S = 10.0
MANIFEST_MAX_BYTES = 1024 * 1024
GITHUB_SHA_RE = re.compile(r"^[0-9a-f]{7,40}$", re.IGNORECASE)


def _normalize_github_origin(origin: str) -> str | None:
    origin = origin.strip()
    if not origin:
        return None
    if origin.startswith("git@github.com:"):
        origin = f"https://github.com/{origin[len('git@github.com:'):]}"
    if origin.startswith("github.com/"):
        origin = f"https://{origin}"
    if origin.startswith("http://") or origin.startswith("https://"):
        parsed = urlparse(origin)
        if parsed.netloc.lower() != "github.com":
            return None
        path = parsed.path.strip("/")
    else:
        path = origin.strip("/")
    if path.endswith(".git"):
        path = path[:-4]
    parts = path.split("/")
    if len(parts) < 2:
        return None
    owner, repo = parts[0], parts[1]
    if not owner or not repo:
        return None
    return f"https://github.com/{owner}/{repo}"


def _github_manifest_candidates(origin_url: str, origin_sha: str) -> list[str] | None:
    origin = _normalize_github_origin(origin_url)
    if not origin or not origin_sha or not GITHUB_SHA_RE.match(origin_sha):
        return None
    parsed = urlparse(origin)
    parts = parsed.path.strip("/").split("/")
    if len(parts) < 2:
        return None
    owner, repo = parts[0], parts[1]
    raw_root = f"https://raw.githubusercontent.com/{owner}/{repo}/{origin_sha}"
    return [f"{raw_root}{suffix}" for suffix in MANIFEST_PATHS]


def validate_manifest(manifest: dict) -> dict:
    """
    mcp.json を最小必須スキーマで検証する。
    必須: name/version/description/endpoints/tools（endpoints/tools は非空）。
    """
    if not isinstance(manifest, dict):
        raise ValueError("manifest は dict である必要があります")

    for key in ("name", "version", "description", "endpoints", "tools"):
        if key not in manifest:
            raise ValueError(f"必須フィールド {key} がありません")

    if not isinstance(manifest["name"], str) or not manifest["name"].strip():
        raise ValueError("name は非空文字列である必要があります")
    if not isinstance(manifest["version"], str) or not VERSION_RE.match(
        manifest["version"]
    ):
        raise ValueError("version は semver 形式である必要があります")
    if (
        not isinstance(manifest["description"], str)
        or not manifest["description"].strip()
    ):
        raise ValueError("description は非空文字列である必要があります")

    endpoints = manifest["endpoints"]
    if not isinstance(endpoints, list) or not endpoints:
        raise ValueError("endpoints は非空リストである必要があります")
    for ep in endpoints:
        if not isinstance(ep, dict):
            raise ValueError("endpoint は dict である必要があります")
        for key in ("name", "url", "protocol"):
            if key not in ep or not isinstance(ep[key], str) or not ep[key].strip():
                raise ValueError(f"endpoint の {key} は非空文字列が必要です")
        if ep["protocol"] not in {"http", "https", "ws", "wss"}:
            raise ValueError("protocol は http/https/ws/wss のいずれかが必要です")
        auth = ep.get("auth") or {"type": "none"}
        if not isinstance(auth, dict):
            raise ValueError("auth は dict である必要があります")
        auth_type = auth.get("type", "none")
        if auth_type not in {"none", "bearer", "basic", "mtls"}:
            raise ValueError("auth.type は none/bearer/basic/mtls のいずれかが必要です")
        ep["auth"] = {"type": auth_type, "token": auth.get("token", "") or None}

    tools = manifest["tools"]
    if not isinstance(tools, list) or not tools:
        raise ValueError("tools は非空リストである必要があります")
    for tool in tools:
        if not isinstance(tool, dict):
            raise ValueError("tool は dict である必要があります")
        for key in ("name", "description"):
            if key not in tool:
                raise ValueError(f"tool の {key} は必須です")
        if not isinstance(tool["name"], str) or not tool["name"].strip():
            raise ValueError("tool.name は非空文字列が必要です")
        if not isinstance(tool["description"], str) or not tool["description"].strip():
            raise ValueError("tool.description は非空文字列が必要です")
        inputs_schema = tool.get("inputs_schema")
        if inputs_schema is None:
            inputs_schema = tool.get("input_schema") or tool.get("args")
        if inputs_schema is None:
            raise ValueError("tool.inputs_schema は必須です")
        if not isinstance(inputs_schema, dict):
            raise ValueError("tool.inputs_schema は dict が必要です")
        outputs_schema = tool.get("outputs_schema")
        if outputs_schema is None:
            outputs_schema = tool.get("output_schema")
        if outputs_schema is None:
            raise ValueError("tool.outputs_schema は必須です")
        if not isinstance(outputs_schema, dict):
            raise ValueError("tool.outputs_schema は dict が必要です")

    return manifest


def static_scan(server: dict) -> dict:
    """
    Perform static scan on a server (manifest/schema checks).

    Args:
        server: Server dict from registry

    Returns:
        Scan result dict with status and findings
    """

    def _fail(reason: str) -> dict:
        return {
            "status": "fail",
            "reason": reason,
            "findings": [
                {"code": reason, "severity": "high", "message": reason}
            ],
            "scan_type": "static",
        }

    def _fetch_manifest(candidates: list[str]) -> dict:
        last_error = ""
        result = _fail("manifest_fetch_failed")
        for url in candidates:
            try:
                resp = httpx.get(url, timeout=MANIFEST_TIMEOUT_S)
            except httpx.TimeoutException:
                last_error = "timeout"
                continue
            except httpx.RequestError:
                last_error = "request_error"
                continue
            if resp.status_code != 200:
                last_error = f"http_status:{resp.status_code}"
                continue
            if resp.content and len(resp.content) > MANIFEST_MAX_BYTES:
                result = _fail("manifest_too_large")
                break
            try:
                manifest = resp.json()
            except ValueError:
                last_error = "manifest_invalid_json"
                continue
            try:
                validate_manifest(manifest)
            except ValueError:
                last_error = "manifest_invalid_schema"
                continue
            result = {
                "status": "pass",
                "reason": "manifest_valid",
                "findings": [],
                "scan_type": "static",
            }
            break
        if result["status"] != "pass" and last_error:
            result = _fail(f"manifest_fetch_failed:{last_error}")
        return result

    origin_url = str(server.get("origin_url") or "").strip()
    origin_sha = str(server.get("origin_sha") or "").strip()
    manifest_source = "github" if (origin_url and origin_sha) else "missing"
    if not origin_url or not origin_sha:
        result = _fail("origin_missing")
    else:
        candidates = _github_manifest_candidates(origin_url, origin_sha)
        if not candidates:
            result = _fail("origin_invalid")
        else:
            result = _fetch_manifest(candidates)

    # Emit mcp_scan_run evidence
    try:
        evidence_path = os.environ.get(
            "MCP_GATEWAY_EVIDENCE_PATH", "observability/policy/ci_evidence.jsonl"
        )
        event = {
            "event": "mcp_scan_run",
            "actor": "scanner",
            "trigger_source": "static_scan",
            "server_id": server.get("server_id", server.get("name", "unknown")),
            "scan_type": "static",
            "status": result["status"],
            "findings_count": len(result.get("findings", [])),
        }
        if result.get("reason"):
            event["reason"] = result["reason"]
        if origin_url:
            event["origin_url"] = origin_url
        if origin_sha:
            event["origin_sha"] = origin_sha
        event["manifest_source"] = manifest_source
        evidence.append(event, path=evidence_path)
    except Exception:
        # Evidence emission failure should not break scan
        pass

    return result


def safety_scan(
    server: dict, run_id: str | None = None, artifacts_root: Path | None = None
) -> dict:
    """
    Perform MCPSafetyScanner scan (attempts real execution via subprocess).

    Execution flow:
    1. Check if 'mcpsafety' command is available in PATH
    2. If not available → return skip with reason
    3. If available → execute: mcpsafety scan --url <server_url> --format json
    4. Parse JSON output and map to our findings format
    5. Classify status based on severity

    Args:
        server: Server dict from registry (must have 'base_url')

    Returns:
        Scan result dict with:
        - status: pass/warn/fail/skip
        - findings: List of vulnerability findings
        - counts: p0/p1/p2/p3 数
        - report_path/report_sha256（artifact 保存時）
        - skip_reason: If status==skip, explains why
        - scan_type: "mcpsafety"
    """
    # Check if mcpsafety is available
    mcpsafety_path = shutil.which("mcpsafety")
    if not mcpsafety_path:
        return {
            "status": "skip",
            "reason": "mcpsafety command not found in PATH - install via: pip install mcpsafety",
            "findings": [],
            "scan_type": "mcpsafety",
        }

    # Attempt to execute mcpsafety
    try:
        result = subprocess.run(
            [
                "mcpsafety",
                "scan",
                "--url",
                server.get("base_url", ""),
                "--format",
                "json",
            ],
            capture_output=True,
            text=True,
            timeout=60,  # 60 second timeout
            check=False,  # Don't raise on non-zero exit
        )

        # Parse JSON output
        if result.returncode == 0 and result.stdout:
            try:
                scan_data = json.loads(result.stdout)
                findings = []

                vulns = scan_data.get("vulnerabilities", [])
                for vuln in vulns:
                    findings.append(
                        {
                            "code": vuln.get("rule_id", vuln.get("type", "unknown")),
                            "severity": vuln.get("severity", "medium").lower(),
                            "message": vuln.get("message", vuln.get("description", "")),
                            "location": vuln.get("location", ""),
                        }
                    )

                counts = {"p0": 0, "p1": 0, "p2": 0, "p3": 0}
                for f in findings:
                    sev = f.get("severity", "").lower()
                    if sev in {"critical", "high"}:
                        counts["p0"] += 1
                    elif sev in {"medium"}:
                        counts["p1"] += 1
                    elif sev in {"low"}:
                        counts["p2"] += 1
                    else:
                        counts["p3"] += 1

                if counts["p0"] > 0:
                    status = "fail"
                    blocked_by = "P0"
                elif counts["p1"] > 0:
                    status = "fail"
                    blocked_by = "P1"
                elif counts["p2"] > 0 or counts["p3"] > 0:
                    status = "warn"
                    blocked_by = ""
                else:
                    status = "pass"
                    blocked_by = ""

                artifact_path_str = None
                artifact_sha = None
                if run_id:
                    artifacts_dir = (artifacts_root or Path("artifacts/scan")) / run_id
                    artifacts_dir.mkdir(parents=True, exist_ok=True)
                    artifact_path = artifacts_dir / "report.json"
                    artifact_path.write_text(
                        result.stdout, encoding="utf-8", newline="\n"
                    )
                    artifact_bytes = artifact_path.read_bytes()
                    artifact_sha = sha256(artifact_bytes).hexdigest()
                    artifact_path_str = str(artifact_path)

                summary = scan_data.get("summary", {})

                # Emit mcp_scan_run evidence
                try:
                    evidence_path = os.environ.get(
                        "MCP_GATEWAY_EVIDENCE_PATH",
                        "observability/policy/ci_evidence.jsonl",
                    )
                    evidence.append(
                        {
                            "event": "mcp_scan_run",
                            "actor": "scanner",
                            "trigger_source": "safety_scan",
                            "server_id": server.get(
                                "server_id", server.get("name", "unknown")
                            ),
                            "scan_type": "mcpsafety",
                            "status": status,
                            "findings_count": len(findings),
                            "counts": counts,
                        },
                        path=evidence_path,
                    )
                except Exception:
                    # Evidence emission failure should not break scan
                    pass

                return {
                    "status": status,
                    "blocked_by": blocked_by,
                    "findings": findings,
                    "counts": counts,
                    "scan_type": "mcpsafety",
                    "handshake": scan_data.get("handshake", summary.get("handshake")),
                    "latency_ms": scan_data.get(
                        "latency_ms", summary.get("latency_ms")
                    ),
                    "command_surface": scan_data.get(
                        "command_surface", summary.get("command_surface")
                    ),
                    "report_path": artifact_path_str,
                    "report_sha256": artifact_sha,
                }
            except json.JSONDecodeError:
                # Failed to parse output
                return {
                    "status": "skip",
                    "reason": f"Failed to parse mcpsafety output: {result.stdout[:200]}",
                    "findings": [],
                    "scan_type": "mcpsafety",
                }
        else:
            # Command failed or no output
            return {
                "status": "skip",
                "reason": f"mcpsafety execution failed: {result.stderr[:200] if result.stderr else 'no error output'}",
                "findings": [],
                "scan_type": "mcpsafety",
            }

    except subprocess.TimeoutExpired:
        return {
            "status": "skip",
            "reason": "mcpsafety scan timed out after 60 seconds",
            "findings": [],
            "scan_type": "mcpsafety",
        }
    except Exception as e:
        return {
            "status": "skip",
            "reason": f"mcpsafety scan error: {str(e)}",
            "findings": [],
            "scan_type": "mcpsafety",
        }


def run_scan(
    db: Any,
    server_id: int,
    scan_types: list[str] = ["static"],
    artifacts_root: Path | None = None,
) -> dict:
    """
    Run scans on a server and save results to registry and evidence.

    Args:
        db: Database instance
        server_id: Server ID to scan
        scan_types: List of scan types to run (static, mcpsafety)
        artifacts_root: Artifact 出力先のベースパス（省略時 artifacts/scan）

    Returns:
        Dict with run_id and scan results
    """
    run_id = str(uuid.uuid4())
    server = registry.get_server(db, server_id)

    if not server:
        raise ValueError(f"Server {server_id} not found")

    results = []

    for scan_type in scan_types:
        import time as _time

        _scan_t0 = _time.perf_counter()
        started_at = datetime.now(timezone.utc).isoformat()

        if scan_type == "static":
            result = static_scan(server)
        elif scan_type == "mcpsafety":
            result = safety_scan(server, run_id=run_id, artifacts_root=artifacts_root)
        elif scan_type == "semantic":
            # Gemini-powered semantic scan (requires GOOGLE_API_KEY)
            tools_exposed = []
            try:
                import sqlite_utils as _su

                allowlist_row = next(
                    db["allowlist"].rows_where(
                        "server_id = ?", [server_id]
                    ),
                    None,
                )
                if allowlist_row and allowlist_row.get("tools_exposed"):
                    import json as _json

                    raw = allowlist_row["tools_exposed"]
                    tools_exposed = (
                        _json.loads(raw) if isinstance(raw, str) else raw
                    )
            except Exception:
                pass
            # Wrap tools_exposed as a manifest-like dict for semantic_scan
            manifest_like = {"tools": tools_exposed} if tools_exposed else None
            result = semantic_scan(server, manifest_like)
        else:
            raise ValueError(f"Unknown scan type: {scan_type}")

        ended_at = datetime.now(timezone.utc).isoformat()

        # Save to registry with actual timestamps
        registry.save_scan_result(
            db,
            server_id=server_id,
            run_id=run_id,
            scan_type=scan_type,
            status=result["status"],
            findings=result.get("findings", []),
            started_at=started_at,
            ended_at=ended_at,
        )

        results.append(result)

    # Emit evidence event
    total_findings = sum(len(r.get("findings", [])) for r in results)
    statuses = [str(r.get("status") or "").lower() for r in results]
    event_status = "fail"
    if statuses:
        if any(status == "fail" for status in statuses):
            event_status = "fail"
        elif any(status == "skip" for status in statuses):
            # スキャン未実行/失敗は失格扱い（fail-closed）
            event_status = "fail"
        elif any(status == "warn" for status in statuses):
            event_status = "warn"
        elif any(status not in {"pass", "ok"} for status in statuses):
            event_status = "fail"
        else:
            event_status = "pass"

    mcpsafety_result = next(
        (r for r in results if r.get("scan_type") == "mcpsafety"), None
    )
    evidence.append(
        {
            "event": "mcp_scan_run",
            "run_id": run_id,
            "server_id": server_id,
            "server_name": server["name"],
            "scan_types": scan_types,
            "status": event_status,
            "blocked_by": (mcpsafety_result or {}).get("blocked_by", ""),
            "findings_total": total_findings,
            "p0": (mcpsafety_result or {}).get("counts", {}).get("p0", 0),
            "p1": (mcpsafety_result or {}).get("counts", {}).get("p1", 0),
            "p2": (mcpsafety_result or {}).get("counts", {}).get("p2", 0),
            "p3": (mcpsafety_result or {}).get("counts", {}).get("p3", 0),
            "report_path": (mcpsafety_result or {}).get("report_path"),
            "report_sha256": (mcpsafety_result or {}).get("report_sha256"),
            "findings_count": total_findings,
        }
    )

    # Emit registry snapshot evidence (counts only)
    try:
        active_ids = {
            int(row.get("server_id"))
            for row in db["allowlist"].rows_where("status = ?", ["active"])
            if row.get("server_id") is not None
        }
        revoked_ids = {
            int(row.get("server_id"))
            for row in db["allowlist"].rows_where("status = ?", ["revoked"])
            if row.get("server_id") is not None
        }
        evidence.append(
            {
                "event": "registry_snapshot",
                "actor": "scanner",
                "trigger_source": "run_scan",
                "snapshot_id": str(uuid.uuid4()),
                "active_servers": len(active_ids),
                "revoked_servers": len(revoked_ids),
            }
        )
    except Exception:
        pass

    summary = {
        "status": event_status,
        "findings_total": total_findings,
        "skip_count": sum(1 for status in statuses if status == "skip"),
    }
    return {
        "run_id": run_id,
        "server_id": server_id,
        "results": results,
        "summary": summary,
    }


def semantic_scan(server: dict, manifest: dict | None = None) -> dict:
    """Perform Gemini 3 semantic analysis on tool descriptions.

    Analyzes tool names, descriptions, and schemas for suspicious patterns
    that static regex checks would miss (e.g., social engineering in descriptions,
    hidden capabilities, deceptive naming).

    Args:
        server: Server dict from registry
        manifest: Optional pre-fetched manifest dict

    Returns:
        Scan result dict with status and findings
    """
    api_key = os.getenv(GEMINI_API_KEY_ENV)
    if not api_key:
        return {
            "status": "skip",
            "reason": "GOOGLE_API_KEY not set",
            "findings": [],
            "scan_type": "semantic",
            "eval_method": "skipped",
        }

    tools_info = []
    if manifest and isinstance(manifest.get("tools"), list):
        for tool in manifest["tools"]:
            tools_info.append(
                {
                    "name": tool.get("name", ""),
                    "description": tool.get("description", ""),
                    "inputs_schema": tool.get(
                        "inputs_schema", tool.get("input_schema", {})
                    ),
                    "outputs_schema": tool.get(
                        "outputs_schema", tool.get("output_schema", {})
                    ),
                }
            )

    if not tools_info:
        return {
            "status": "skip",
            "reason": "no_tools_to_analyze",
            "findings": [],
            "scan_type": "semantic",
            "eval_method": "skipped",
        }

    prompt = (
        "You are a security analyst reviewing MCP server tool definitions "
        "for hidden threats.\n"
        "Analyze each tool for:\n"
        "1. Data exfiltration risk (does it send data to external services?)\n"
        "2. Privilege escalation (does it request excessive permissions?)\n"
        "3. Command injection (can inputs be used to execute arbitrary commands?)\n"
        "4. Prompt injection (does the description contain instructions "
        "that could manipulate an LLM?)\n"
        "5. Resource abuse (could it consume excessive compute/network?)\n"
        "6. Deceptive naming (does the tool name misrepresent its function?)\n"
        "7. Known threats (use Google Search to check if any URLs, domains, or "
        "package names in the tool definitions are associated with known attacks)\n\n"
        f"Server: {server.get('name', 'unknown')}\n"
        f"Tools:\n{json.dumps(tools_info, indent=2)}\n"
    )

    try:
        from google import genai
        from google.genai import types

        client = genai.Client(api_key=api_key)
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=SemanticScanResult,
                thinking_config=types.ThinkingConfig(thinking_level="high"),
                tools=[types.Tool(google_search=types.GoogleSearch())],
                temperature=0.0,
                max_output_tokens=2048,
                seed=42,
            ),
        )
        scan_result = SemanticScanResult.model_validate_json(response.text)
    except Exception as exc:
        logger.warning("Gemini semantic scan failed: %s", exc)
        return {
            "status": "skip",
            "reason": f"gemini_error: {exc}",
            "findings": [],
            "scan_type": "semantic",
            "eval_method": "error",
        }

    findings = []
    for analysis in scan_result.tool_analyses:
        if analysis.risk_level in ("critical", "high", "medium"):
            findings.append(
                {
                    "code": f"semantic_{analysis.threat_type}",
                    "severity": analysis.risk_level,
                    "message": f"[{analysis.tool_name}] {analysis.description}",
                    "confidence": analysis.confidence,
                }
            )

    has_critical = any(f["severity"] == "critical" for f in findings)
    has_high = any(f["severity"] == "high" for f in findings)
    if has_critical or has_high:
        status = "fail"
    elif findings:
        status = "warn"
    else:
        status = "pass"

    # Evidence
    try:
        evidence_path = os.environ.get(
            "MCP_GATEWAY_EVIDENCE_PATH",
            "observability/policy/ci_evidence.jsonl",
        )
        evidence.append(
            {
                "event": "mcp_scan_run",
                "actor": "scanner",
                "trigger_source": "semantic_scan",
                "server_id": server.get(
                    "server_id", server.get("name", "unknown")
                ),
                "scan_type": "semantic",
                "status": status,
                "findings_count": len(findings),
                "gemini_model": GEMINI_MODEL,
                "overall_risk": scan_result.overall_risk,
                "recommended_action": scan_result.recommended_action,
            },
            path=evidence_path,
        )
    except Exception:
        pass

    return {
        "status": status,
        "findings": findings,
        "scan_type": "semantic",
        "eval_method": "gemini",
        "gemini_model": GEMINI_MODEL,
        "overall_risk": scan_result.overall_risk,
        "recommended_action": scan_result.recommended_action,
        "summary": scan_result.summary,
        "tool_analyses_count": len(scan_result.tool_analyses),
    }


def schedule_retest(db: Any, server_id: int, reason: str, delay_hours: int = 24) -> str:
    """
    Schedule a retest for a server (MVP: stub that emits Evidence only).

    Note: In production, enqueue actual job to job scheduler (celery/rq/etc).
    Currently called for quarantine decisions only.

    Args:
        db: Database instance
        server_id: Server ID to retest
        reason: Reason for retest (e.g., "quarantine_decision", "deny_decision")
        delay_hours: Hours to wait before retest

    Returns:
        Retest run_id
    """
    run_id = str(uuid.uuid4())
    scheduled_at = (
        datetime.now(timezone.utc) + timedelta(hours=delay_hours)
    ).isoformat()

    # Get server info
    server = registry.get_server(db, server_id)
    server_name = server["name"] if server else "unknown"

    evidence.append(
        {
            "event": "retest_scheduled",
            "run_id": run_id,
            "server_id": server_id,
            "server_name": server_name,
            "reason": reason,
            "scheduled_at": scheduled_at,
            "delay_hours": delay_hours,
        }
    )

    return run_id


# ---------------------------------------------------------------------------
# Advanced Attack Detectors (Signature Cloaking, Bait-and-Switch, Shadowing)
# ---------------------------------------------------------------------------

# Well-known MCP tool names for shadowing detection
_WELL_KNOWN_TOOLS: frozenset[str] = frozenset(
    {
        "read_file",
        "write_file",
        "list_directory",
        "search_files",
        "execute_command",
        "browser_navigate",
        "browser_click",
        "browser_type",
        "browser_snapshot",
        "browser_screenshot",
        "create_file",
        "delete_file",
        "move_file",
        "copy_file",
        "get_file_info",
        "run_terminal_command",
        "edit_file",
        "read_resource",
        "list_tools",
        "call_tool",
    }
)

# Levenshtein-like similarity (simple ratio) for shadowing detection
def _name_similarity(a: str, b: str) -> float:
    """Return similarity ratio [0.0, 1.0] between two tool names."""
    a_lower, b_lower = a.lower().replace("-", "_"), b.lower().replace("-", "_")
    if a_lower == b_lower:
        return 1.0
    if not a_lower or not b_lower:
        return 0.0
    # Simple character-based similarity
    shorter, longer = sorted([a_lower, b_lower], key=len)
    if shorter in longer:
        return len(shorter) / len(longer)
    matches = sum(1 for c1, c2 in zip(shorter, longer) if c1 == c2)
    return matches / max(len(shorter), len(longer))


# Suspicious schema keywords that indicate capabilities beyond stated purpose
_DANGEROUS_SCHEMA_KEYWORDS: frozenset[str] = frozenset(
    {
        "password",
        "secret",
        "token",
        "credential",
        "api_key",
        "private_key",
        "credit_card",
        "ssn",
        "authorization",
        "cookie",
        "session_id",
    }
)

# Benign description keywords (tools claiming to be safe/read-only)
_BENIGN_DESCRIPTION_PATTERNS: list[str] = [
    "read-only",
    "readonly",
    "safe",
    "harmless",
    "view only",
    "display",
    "list",
    "get",
    "fetch",
    "query",
]


def detect_signature_cloaking(
    current_tools: list[dict],
    previous_tools: list[dict],
) -> list[dict]:
    """Detect tools whose descriptions changed significantly between scans.

    Signature cloaking: attacker initially registers a benign tool description,
    then later changes it to something malicious while keeping the same name.
    """
    findings: list[dict] = []
    prev_by_name = {t.get("name", ""): t for t in previous_tools if t.get("name")}

    for tool in current_tools:
        name = tool.get("name", "")
        if not name or name not in prev_by_name:
            continue

        prev = prev_by_name[name]
        old_desc = str(prev.get("description", "")).strip()
        new_desc = str(tool.get("description", "")).strip()

        if not old_desc or not new_desc:
            continue

        # Compare word sets for significant semantic drift
        old_words = set(old_desc.lower().split())
        new_words = set(new_desc.lower().split())
        if not old_words:
            continue

        overlap = old_words & new_words
        jaccard = len(overlap) / len(old_words | new_words) if (old_words | new_words) else 1.0

        # Threshold: if less than 40% word overlap, flag as cloaking
        if jaccard < 0.4:
            findings.append(
                {
                    "code": "signature_cloaking",
                    "severity": "critical",
                    "message": (
                        f"[{name}] Description changed significantly "
                        f"(similarity={jaccard:.0%}): "
                        f"'{old_desc[:80]}...' -> '{new_desc[:80]}...'"
                    ),
                    "confidence": min(1.0, 1.0 - jaccard),
                    "tool_name": name,
                    "old_description": old_desc[:200],
                    "new_description": new_desc[:200],
                }
            )

    return findings


def detect_bait_and_switch(tools: list[dict]) -> list[dict]:
    """Detect tools whose schema contradicts their stated purpose.

    Bait-and-switch: a tool claims to be benign (e.g., 'list files') but its
    input/output schema requests sensitive data like passwords or tokens.
    """
    findings: list[dict] = []

    for tool in tools:
        name = str(tool.get("name", ""))
        desc = str(tool.get("description", "")).lower()
        input_schema = tool.get("inputs_schema") or tool.get("input_schema") or {}
        output_schema = tool.get("outputs_schema") or tool.get("output_schema") or {}

        # Check if description claims benign behavior
        is_benign_claim = any(pat in desc for pat in _BENIGN_DESCRIPTION_PATTERNS)

        # Extract all property names from schemas
        schema_fields: set[str] = set()
        for schema in (input_schema, output_schema):
            if isinstance(schema, dict):
                for key in schema.get("properties", {}):
                    schema_fields.add(key.lower())
                # Also check nested required fields
                for req in schema.get("required", []):
                    schema_fields.add(str(req).lower())

        # Also check schema field descriptions for sensitive patterns
        schema_text = json.dumps(input_schema).lower() + json.dumps(output_schema).lower()

        dangerous_found = schema_fields & _DANGEROUS_SCHEMA_KEYWORDS
        dangerous_in_text = {
            kw for kw in _DANGEROUS_SCHEMA_KEYWORDS if kw in schema_text
        }
        all_dangerous = dangerous_found | dangerous_in_text

        if all_dangerous and is_benign_claim:
            findings.append(
                {
                    "code": "bait_and_switch",
                    "severity": "critical",
                    "message": (
                        f"[{name}] Claims to be benign ('{desc[:60]}') but "
                        f"schema references sensitive fields: {sorted(all_dangerous)}"
                    ),
                    "confidence": 0.85,
                    "tool_name": name,
                    "dangerous_fields": sorted(all_dangerous),
                }
            )
        elif all_dangerous and not is_benign_claim:
            # Still suspicious if dangerous fields present, lower severity
            findings.append(
                {
                    "code": "bait_and_switch",
                    "severity": "high",
                    "message": (
                        f"[{name}] Schema references sensitive fields: "
                        f"{sorted(all_dangerous)}"
                    ),
                    "confidence": 0.6,
                    "tool_name": name,
                    "dangerous_fields": sorted(all_dangerous),
                }
            )

    return findings


def detect_tool_shadowing(tools: list[dict]) -> list[dict]:
    """Detect tools with names suspiciously similar to well-known MCP tools.

    Tool shadowing: attacker registers 'read_fi1e' or 'read-file' to intercept
    calls intended for the legitimate 'read_file' tool.
    """
    findings: list[dict] = []

    for tool in tools:
        name = str(tool.get("name", ""))
        if not name:
            continue

        name_normalized = name.lower().replace("-", "_")

        # Exact match with well-known tool is not shadowing (it IS the tool)
        if name_normalized in _WELL_KNOWN_TOOLS:
            continue

        # Check similarity against each well-known tool
        for known in _WELL_KNOWN_TOOLS:
            sim = _name_similarity(name, known)
            # High similarity but not exact: likely shadowing
            if sim >= 0.75:
                findings.append(
                    {
                        "code": "tool_shadowing",
                        "severity": "critical",
                        "message": (
                            f"[{name}] Suspiciously similar to well-known tool "
                            f"'{known}' (similarity={sim:.0%})"
                        ),
                        "confidence": sim,
                        "tool_name": name,
                        "shadows": known,
                    }
                )
                break  # One match per tool

    return findings


def run_advanced_threat_scan(
    tools: list[dict],
    previous_tools: list[dict] | None = None,
) -> dict:
    """Run all advanced attack detectors on tool definitions.

    Combines: signature cloaking, bait-and-switch, and tool shadowing.

    Args:
        tools: Current tool definitions
        previous_tools: Previous scan's tool definitions (for cloaking detection)

    Returns:
        Scan result dict compatible with run_scan aggregation
    """
    findings: list[dict] = []

    # 1. Signature Cloaking (requires previous scan data)
    if previous_tools:
        findings.extend(detect_signature_cloaking(tools, previous_tools))

    # 2. Bait-and-Switch
    findings.extend(detect_bait_and_switch(tools))

    # 3. Tool Shadowing
    findings.extend(detect_tool_shadowing(tools))

    has_critical = any(f["severity"] == "critical" for f in findings)
    has_high = any(f["severity"] == "high" for f in findings)
    if has_critical:
        status = "fail"
    elif has_high:
        status = "warn"
    elif findings:
        status = "warn"
    else:
        status = "pass"

    # Evidence
    try:
        evidence_path = os.environ.get(
            "MCP_GATEWAY_EVIDENCE_PATH",
            "observability/policy/ci_evidence.jsonl",
        )
        evidence.append(
            {
                "event": "advanced_threat_scan",
                "actor": "scanner",
                "scan_type": "advanced_threats",
                "status": status,
                "findings_count": len(findings),
                "cloaking_count": sum(
                    1 for f in findings if f["code"] == "signature_cloaking"
                ),
                "bait_switch_count": sum(
                    1 for f in findings if f["code"] == "bait_and_switch"
                ),
                "shadowing_count": sum(
                    1 for f in findings if f["code"] == "tool_shadowing"
                ),
            },
            path=evidence_path,
        )
    except Exception:
        pass

    return {
        "status": status,
        "findings": findings,
        "scan_type": "advanced_threats",
        "eval_method": "rule_based",
    }
